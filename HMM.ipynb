{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe91101",
   "metadata": {},
   "source": [
    "## Erdos Insitute Data Science Bootcamp Spring 2023\n",
    "## Final Project: SPY ETF Short-term Price Prediction\n",
    "### Team: Algebros (Members: Sailun Zhan, Xinwu Yang, Aolong Li, Amin Idelhaj, Zongze Liu)\n",
    "### Author for this notebook: Xinwu Yang, Sailun Zhan, Aolong Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10880291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# from datetime import datetime, timedelta, time\n",
    "from hmmlearn import hmm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ea9069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16422, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We first import the 1-min interval open/high/low price data from 4/3/2023 to 6/1/2023. \n",
    "### All the data is available at AlphaVantage. \n",
    "\n",
    "df_min_month1 = pd.read_csv('./data/extended_intraday_SPY_1min_year1month1_adjusted.csv', parse_dates=['time'])\n",
    "df_min_month2 = pd.read_csv('./data/extended_intraday_SPY_1min_year1month2_adjusted.csv', parse_dates=['time'])\n",
    "\n",
    "df_min = pd.merge(df_min_month1, df_min_month2, how = 'outer')\n",
    "\n",
    "\n",
    "### We are only interested in the data during regular trading hours, \n",
    "### so we exclude the data before 9:30 and after 16:00 every day.\n",
    "\n",
    "start_time = pd.to_datetime('9:30').time()\n",
    "end_time = pd.to_datetime('16:00').time()\n",
    "\n",
    "df_min = df_min[(df_min['time'].dt.time >= start_time) & (df_min['time'].dt.time <= end_time)]\n",
    "\n",
    "df_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45240d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16422, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Transform the data into numpy array to prepare for our model\n",
    "\n",
    "data_array = df_min[['open', 'high', 'low']].to_numpy()\n",
    "\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007c0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and test splits\n",
    "### Avoid 9:30 to 11:30 period, since our program uses previous 120 minutes information to do training\n",
    "### In 9:30 to 11:30 period, the previous day info will be used\n",
    "\n",
    "\n",
    "def split(df, n):\n",
    "    np.random.seed(42)\n",
    "    random_index = np.random.choice(range(60, df_min.shape[0]), size=n, replace=False)\n",
    "    while (df.iloc[random_index]['time'].dt.time < pd.to_datetime('11:30').time()).any() :\n",
    "        random_index = np.random.choice(range(60, df_min.shape[0]), size=n, replace=False)\n",
    "    return np.sort(random_index)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b243b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = split(df_min, 4)\n",
    "time_list = df_min['time'].iloc[test_idx]\n",
    "\n",
    "### Append 60 since we want to test our model on the most recent 60 minutes\n",
    "test_idx = np.append(test_idx, [60])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model training and testing\n",
    "### Reference: \"Hidden Markov Model for Stock Trading\" by Nguyet Nguyen\n",
    "\n",
    "num_prediction = 60\n",
    "num_iteration = 10000\n",
    "K = 120\n",
    "\n",
    "MAE_opens, MAE_highs, MAE_lows = [], [], []\n",
    "comparisions = []\n",
    "\n",
    "for i in range(len(test_idx)):\n",
    "    test_index = test_idx[i]\n",
    "    \n",
    "    whole_dataset = data_array[test_index:, :]\n",
    "    predicted_price = np.empty([0,whole_dataset.shape[1]])\n",
    "    \n",
    "\n",
    "    for idx in reversed(range(num_prediction)):\n",
    "            train_dataset = whole_dataset[idx + 1:,:]\n",
    "            num_examples = train_dataset.shape[0]\n",
    "            \n",
    "            if idx == num_prediction-1:\n",
    "                model = hmm.GaussianHMM(n_components=4, covariance_type='diag',  tol=0.0001, n_iter=num_iteration, init_params='stmc')\n",
    "            else: # fit the model using previous computed transmat_, startprob_, means_, covars_\n",
    "                model = hmm.GaussianHMM(n_components=4, covariance_type='full', tol=0.0001, n_iter=num_iteration, init_params = '')\n",
    "                model.transmat_ = transmat_previous\n",
    "                model.startprob_ = startprob_previous\n",
    "                model.means_ = means_previous\n",
    "                model.covars_ = covars_previous\n",
    "            \n",
    "            # flipud since the dataset is sorted in time descending order (from recent to past)\n",
    "            model.fit(np.flipud(train_dataset))\n",
    "            transmat_previous = model.transmat_\n",
    "            startprob_previous = model.startprob_\n",
    "            means_previous = model.means_\n",
    "            covars_previous = model.covars_\n",
    "            \n",
    "            \n",
    "            # predict the price corresponding to whole_dataset[idx]  \n",
    "            iters = 1\n",
    "            previous_probability = []\n",
    "            current_probability = model.score(np.flipud(train_dataset[0:K, :]))\n",
    "            while iters < num_examples / K - 1:\n",
    "                previous_probability = np.append(previous_probability, model.score(np.flipud(train_dataset[iters:iters + K, :])))\n",
    "                iters = iters + 1\n",
    "            \n",
    "            # find the most similar state at time t* to whole_dataset[idx + 1]\n",
    "            # \"most similar\" means P( train_dataset[0:K] | parameters) - P( train_dataset[t*:t*+K]| parameters ) is minimized \n",
    "            # over all possible t* in the past two hours\n",
    "            diff_idx = np.argmin(np.absolute(previous_probability - current_probability))\n",
    "            \n",
    "            # the change y(t+1) - y(t) = y(t*+1) - y(t*)\n",
    "            predicted_change = train_dataset[diff_idx,:] - train_dataset[diff_idx + 1,:]\n",
    "            predicted_price = np.vstack((predicted_price, whole_dataset[idx + 1,:] + predicted_change))\n",
    "    \n",
    "    ### Storing the predictions and corresponding true values\n",
    "    comparisions += [ (np.flipud(whole_dataset[range(num_prediction), 1:3]), predicted_price[:, 1:3]) ]\n",
    "                    \n",
    "\n",
    "    ### Computing the MAE\n",
    "\n",
    "    MAE_open = mean_absolute_error(np.flipud(whole_dataset[range(num_prediction),0]), predicted_price[:,0])\n",
    "    MAE_high = mean_absolute_error(np.flipud(whole_dataset[range(num_prediction),1]), predicted_price[:,1])\n",
    "    MAE_low = mean_absolute_error(np.flipud(whole_dataset[range(num_prediction),2]), predicted_price[:,2])\n",
    "    \n",
    "    MAE_opens += [MAE_open]\n",
    "    MAE_highs += [MAE_high]\n",
    "    MAE_lows += [MAE_low]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: the MAE results might be different from those in the presentation video and slides \n",
    "### because of the train-test split\n",
    "\n",
    "print(MAE_opens[-1])\n",
    "print(MAE_highs[-1])\n",
    "print(MAE_lows[-1])\n",
    "\n",
    "print(np.mean(np.array(MAE_opens)), np.mean(np.array(MAE_highs)), np.mean(np.array(MAE_lows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the predicted price\n",
    "### Observe some potential problem here: low > high/open or high < low/open for some predictions\n",
    "### NOTE: the graph might be different from that in the presentation video and slides because of the train-test split\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "pred_open = plt.plot(range(num_prediction), predicted_price[:,0])\n",
    "pred_high = plt.plot(range(num_prediction), predicted_price[:,1])\n",
    "pred_low = plt.plot(range(num_prediction), predicted_price[:,2])\n",
    "plt.title('Predicted SPY price in 1 hours')\n",
    "plt.legend(('Predicted_open', 'Predicted_high', 'Predicted_low'))\n",
    "plt.xlabel('Time steps (in minute)')\n",
    "plt.ylabel('Price (in US Dollar)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot high price comparison\n",
    "### NOTE: the graph might be different from that in the presentation video and slides because of the train-test split\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "pred = plt.plot(range(num_prediction), predicted_price[:, 1])\n",
    "actual = plt.plot(range(num_prediction),np.flipud(whole_dataset[range(num_prediction),1]))\n",
    "plt.title('SPY price: Predicted high v.s. Actual high')\n",
    "plt.legend(('Predicted_High', 'Actual_High'))\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Price (in US Dollar)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7285561",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot open price comparison\n",
    "### NOTE: the graph might be different from that in the presentation video and slides because of the train-test split\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "pred = plt.plot(range(num_prediction), predicted_price[:, 0])\n",
    "actual = plt.plot(range(num_prediction),np.flipud(whole_dataset[range(num_prediction),0]))\n",
    "plt.title('SPY price: Predicted open v.s. Actual open')\n",
    "plt.legend(('Predicted_Open', 'Actual_Open'))\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Price (in US Dollar)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot low price comparisons\n",
    "### NOTE: the graph might be different from the presentation video and slides because of the train-test split\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "pred = plt.plot(range(num_prediction), predicted_price[:, 2])\n",
    "actual = plt.plot(range(num_prediction),np.flipud(whole_dataset[range(num_prediction),2]))\n",
    "plt.title('SPY price: Predicted low v.s. Actual low')\n",
    "plt.legend(('Predicted_low', 'Actual_low'))\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Price (in US Dollar)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
